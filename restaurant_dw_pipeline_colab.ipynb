{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "title",
      "metadata": {},
      "source": [
        "# ðŸ“Š Restaurant Data Warehouse + ML Pipeline + Scalability (Colab Ready)\n",
        "\n",
        "This notebook lets you:\n",
        "1. Build features + label (return in 30 days).\n",
        "2. Train Decision Tree & Naive Bayes.\n",
        "3. Evaluate with precision, recall, F1, accuracy, ROC-AUC.\n",
        "4. Analyze **Data Mining Scalability**:\n",
        "   - Runtime vs dataset size\n",
        "   - Runtime vs number of features\n",
        "\n",
        "---\n",
        "âœ… All required packages are already pre-installed in Colab: `pandas`, `numpy`, `scikit-learn`, `joblib`, `matplotlib`, `sqlalchemy`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "load_data",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ðŸ“‚ Load dataset directly from GitHub\n",
        "import pandas as pd\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/avinash972/restaurant-dw-ml/main/restaurant_orders.csv\"\n",
        "df_orders = pd.read_csv(url, parse_dates=['timestamp'])\n",
        "print(\"Rows loaded:\", len(df_orders))\n",
        "df_orders.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "feature_eng",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ðŸ”§ Feature Engineering + Label Creation\n",
        "import numpy as np\n",
        "\n",
        "orders = df_orders.copy()\n",
        "orders = orders.sort_values(['customer_id','timestamp']).reset_index(drop=True)\n",
        "\n",
        "# Label: return within 30 days\n",
        "comp = orders[orders['status']=='completed'].sort_values(['customer_id','timestamp']).reset_index(drop=True)\n",
        "comp['next_ts'] = comp.groupby('customer_id')['timestamp'].shift(-1)\n",
        "comp['days_to_next'] = (comp['next_ts'] - comp['timestamp']).dt.days\n",
        "comp['return_30d'] = ((comp['days_to_next'].notna()) & (comp['days_to_next'] <= 30)).astype(int)\n",
        "label_map = comp.set_index('order_id')['return_30d'].to_dict()\n",
        "orders['return_30d'] = orders['order_id'].map(label_map).fillna(0).astype(int)\n",
        "\n",
        "# Features\n",
        "orders['prev_ts'] = orders.groupby('customer_id')['timestamp'].shift(1)\n",
        "orders['recency_days'] = (orders['timestamp'] - orders['prev_ts']).dt.days.fillna(999).astype(int)\n",
        "orders['avg_ticket'] = orders['total_amount'] / orders['num_items'].replace(0,1)\n",
        "orders['order_hour'] = orders['timestamp'].dt.hour\n",
        "orders['is_weekend'] = orders['timestamp'].dt.dayofweek.isin([5,6]).astype(int)\n",
        "\n",
        "# 90-day frequency\n",
        "freq90 = []\n",
        "for idx,row in orders.iterrows():\n",
        "    cust = row['customer_id']; ts=row['timestamp']\n",
        "    prior = orders[(orders['customer_id']==cust) & (orders['timestamp']<ts) & (orders['timestamp']>=ts-pd.Timedelta(days=90)) & (orders['status']=='completed')]\n",
        "    freq90.append(len(prior))\n",
        "orders['freq_90d'] = freq90\n",
        "\n",
        "# Final modeling dataset\n",
        "model_df = orders[orders['status']=='completed'].copy()\n",
        "print('Model dataset rows:', len(model_df))\n",
        "model_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "train_models",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ðŸ¤– Train & Evaluate Models\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report\n",
        "import joblib, os\n",
        "\n",
        "split_date = pd.to_datetime('2024-07-01')\n",
        "train = model_df[model_df['timestamp'] < split_date].copy()\n",
        "test = model_df[model_df['timestamp'] >= split_date].copy()\n",
        "\n",
        "feature_cols = ['total_amount','num_items','recency_days','avg_ticket','order_hour','is_weekend','freq_90d']\n",
        "train = pd.get_dummies(train, columns=['channel'], drop_first=True)\n",
        "test = pd.get_dummies(test, columns=['channel'], drop_first=True)\n",
        "for c in ['channel_takeaway','channel_delivery']:\n",
        "    if c not in train.columns: train[c]=0\n",
        "    if c not in test.columns: test[c]=0\n",
        "feature_cols += ['channel_takeaway','channel_delivery']\n",
        "\n",
        "X_train, y_train = train[feature_cols].fillna(0), train['return_30d']\n",
        "X_test, y_test = test[feature_cols].fillna(0), test['return_30d']\n",
        "\n",
        "dt = DecisionTreeClassifier(max_depth=6, min_samples_leaf=5, random_state=42)\n",
        "nb = GaussianNB()\n",
        "\n",
        "dt.fit(X_train, y_train)\n",
        "nb.fit(X_train, y_train)\n",
        "\n",
        "y_dt, y_nb = dt.predict(X_test), nb.predict(X_test)\n",
        "p_dt, p_nb = dt.predict_proba(X_test)[:,1], nb.predict_proba(X_test)[:,1]\n",
        "\n",
        "def metrics(y_true,y_pred,y_proba):\n",
        "    return dict(\n",
        "        accuracy=round(accuracy_score(y_true,y_pred),3),\n",
        "        precision=round(precision_score(y_true,y_pred,zero_division=0),3),\n",
        "        recall=round(recall_score(y_true,y_pred,zero_division=0),3),\n",
        "        f1=round(f1_score(y_true,y_pred,zero_division=0),3),\n",
        "        roc_auc=round(roc_auc_score(y_true,y_proba) if len(set(y_true))>1 else float('nan'),3)\n",
        "    )\n",
        "\n",
        "print('Decision Tree:', metrics(y_test,y_dt,p_dt))\n",
        "print('Naive Bayes:', metrics(y_test,y_nb,p_nb))\n",
        "\n",
        "print('\\nClassification Report (Decision Tree):\\n', classification_report(y_test,y_dt,zero_division=0))\n",
        "print('\\nClassification Report (Naive Bayes):\\n', classification_report(y_test,y_nb,zero_division=0))\n",
        "\n",
        "os.makedirs('outputs', exist_ok=True)\n",
        "joblib.dump(dt, 'outputs/decision_tree.joblib')\n",
        "joblib.dump(nb, 'outputs/naive_bayes.joblib')\n",
        "model_df.to_csv('outputs/model_dataset.csv', index=False)\n",
        "print('Artifacts saved in outputs/')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "scalability_header",
      "metadata": {},
      "source": [
        "## âš¡ Data Mining Scalability\n",
        "\n",
        "We now test how models behave as:\n",
        "1. **Dataset size increases** (runtime).\n",
        "2. **Number of features increases** (runtime)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "scalability_code",
      "metadata": {},
      "outputs": [],
      "source": [
        "import time, matplotlib.pyplot as plt\n",
        "\n",
        "sizes = [1000, 2000, 4000, 8000, len(X_train)]\n",
        "dt_times, nb_times = [], []\n",
        "\n",
        "for s in sizes:\n",
        "    Xs, ys = X_train[:s], y_train[:s]\n",
        "    \n",
        "    t0 = time.time(); DecisionTreeClassifier(max_depth=6).fit(Xs, ys); dt_times.append(time.time()-t0)\n",
        "    t0 = time.time(); GaussianNB().fit(Xs, ys); nb_times.append(time.time()-t0)\n",
        "\n",
        "plt.plot(sizes, dt_times, 'o-', label='Decision Tree')\n",
        "plt.plot(sizes, nb_times, 'o-', label='Naive Bayes')\n",
        "plt.xlabel('Training Set Size (rows)'); plt.ylabel('Training Time (s)'); plt.title('Scalability: Rows vs Time')\n",
        "plt.legend(); plt.show()\n",
        "\n",
        "# Feature scalability: duplicate columns artificially\n",
        "feat_counts = [len(feature_cols), len(feature_cols)*2, len(feature_cols)*4]\n",
        "dt_feat_times, nb_feat_times = [], []\n",
        "\n",
        "for f in feat_counts:\n",
        "    Xf = pd.concat([X_train]*int(f/len(feature_cols)), axis=1)\n",
        "    \n",
        "    t0 = time.time(); DecisionTreeClassifier(max_depth=6).fit(Xf, y_train); dt_feat_times.append(time.time()-t0)\n",
        "    t0 = time.time(); GaussianNB().fit(Xf, y_train); nb_feat_times.append(time.time()-t0)\n",
        "\n",
        "plt.plot(feat_counts, dt_feat_times, 'o-', label='Decision Tree')\n",
        "plt.plot(feat_counts, nb_feat_times, 'o-', label='Naive Bayes')\n",
        "plt.xlabel('Number of Features'); plt.ylabel('Training Time (s)'); plt.title('Scalability: Features vs Time')\n",
        "plt.legend(); plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
