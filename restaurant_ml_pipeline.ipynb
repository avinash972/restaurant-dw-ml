{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ“Š Restaurant Orders ML Pipeline (Colab Ready)\n",
        "\n",
        "This notebook lets you:\n",
        "1. Load restaurant orders dataset (CSV or GitHub link).\n",
        "2. Build features + 30-day return label.\n",
        "3. Train Decision Tree & Naive Bayes.\n",
        "4. Evaluate metrics and generate graphs.\n",
        "5. Compare scalability and save artifacts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "!pip install pandas numpy scikit-learn joblib matplotlib seaborn memory_profiler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Load dataset from GitHub or upload CSV\n",
        "import pandas as pd\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/avinash972/restaurant-dw-ml/main/restaurant_orders.csv'\n",
        "df_orders = pd.read_csv(url, parse_dates=['timestamp'])\n",
        "print('Rows loaded:', len(df_orders))\n",
        "df_orders.head()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Feature Engineering + 90-day frequency\n",
        "import numpy as np\n",
        "orders = df_orders.copy()\n",
        "orders = orders.sort_values(['customer_id','timestamp']).reset_index(drop=True)\n",
        "\n",
        "# Label: return within 30 days\n",
        "comp = orders[orders['status'] == 'completed'].sort_values(['customer_id','timestamp']).reset_index(drop=True)\n",
        "comp['next_ts'] = comp.groupby('customer_id')['timestamp'].shift(-1)\n",
        "comp['days_to_next'] = (comp['next_ts'] - comp['timestamp']).dt.days\n",
        "comp['return_30d'] = ((comp['days_to_next'].notna()) & (comp['days_to_next'] <= 30)).astype(int)\n",
        "label_map = comp.set_index('order_id')['return_30d'].to_dict()\n",
        "orders['return_30d'] = orders['order_id'].map(label_map).fillna(0).astype(int)\n",
        "\n",
        "# Features\n",
        "orders['prev_ts'] = orders.groupby('customer_id')['timestamp'].shift(1)\n",
        "orders['recency_days'] = (orders['timestamp'] - orders['prev_ts']).dt.days.fillna(999).astype(int)\n",
        "orders['avg_ticket'] = orders['total_amount'] / orders['num_items'].replace(0,1)\n",
        "orders['order_hour'] = orders['timestamp'].dt.hour\n",
        "orders['is_weekend'] = orders['timestamp'].dt.dayofweek.isin([5,6]).astype(int)\n",
        "\n",
        "# 90-day frequency\n",
        "freq90 = []\n",
        "for idx, row in orders.iterrows():\n",
        "    cust = row['customer_id']\n",
        "    ts = row['timestamp']\n",
        "    prior = orders[(orders['customer_id'] == cust) &\n",
        "                   (orders['timestamp'] < ts) &\n",
        "                   (orders['timestamp'] >= ts - pd.Timedelta(days=90)) &\n",
        "                   (orders['status'] == 'completed')]\n",
        "    freq90.append(len(prior))\n",
        "orders['freq_90d'] = freq90\n",
        "\n",
        "# Modeling dataset\n",
        "model_df = orders[orders['status'] == 'completed'].copy()\n",
        "print('Model dataset rows:', len(model_df))\n",
        "model_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Train & Evaluate Models\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report, confusion_matrix, roc_curve, auc\n",
        "import joblib, os, matplotlib.pyplot as plt, seaborn as sns\n",
        "\n",
        "# Train/test split\n",
        "split_date = pd.to_datetime('2024-07-01')\n",
        "train = model_df[model_df['timestamp'] < split_date].copy()\n",
        "test = model_df[model_df['timestamp'] >= split_date].copy()\n",
        "\n",
        "feature_cols = ['total_amount','num_items','recency_days','avg_ticket','order_hour','is_weekend','freq_90d']\n",
        "train = pd.get_dummies(train, columns=['channel'], drop_first=True)\n",
        "test = pd.get_dummies(test, columns=['channel'], drop_first=True)\n",
        "for c in ['channel_takeaway','channel_delivery']:\n",
        "    if c not in train.columns: train[c]=0\n",
        "    if c not in test.columns: test[c]=0\n",
        "feature_cols += ['channel_takeaway','channel_delivery']\n",
        "\n",
        "X_train, y_train = train[feature_cols].fillna(0), train['return_30d']\n",
        "X_test, y_test = test[feature_cols].fillna(0), test['return_30d']\n",
        "\n",
        "# Train models\n",
        "dt = DecisionTreeClassifier(max_depth=6, min_samples_leaf=5, random_state=42)\n",
        "nb = GaussianNB()\n",
        "\n",
        "dt.fit(X_train, y_train)\n",
        "nb.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_dt, y_nb = dt.predict(X_test), nb.predict(X_test)\n",
        "p_dt, p_nb = dt.predict_proba(X_test)[:,1], nb.predict_proba(X_test)[:,1]\n",
        "\n",
        "# Metrics function\n",
        "def metrics(y_true, y_pred, y_proba):\n",
        "    return dict(\n",
        "        accuracy = round(accuracy_score(y_true, y_pred),3),\n",
        "        precision = round(precision_score(y_true, y_pred, zero_division=0),3),\n",
        "        recall = round(recall_score(y_true, y_pred, zero_division=0),3),\n",
        "        f1 = round(f1_score(y_true, y_pred, zero_division=0),3),\n",
        "        roc_auc = round(roc_auc_score(y_true, y_proba) if len(set(y_true))>1 else float('nan'),3)\n",
        "    )\n",
        "\n",
        "dt_metrics = metrics(y_test, y_dt, p_dt)\n",
        "nb_metrics = metrics(y_test, y_nb, p_nb)\n",
        "\n",
        "print('Decision Tree:', dt_metrics)\n",
        "print('Naive Bayes:', nb_metrics)\n",
        "\n",
        "print('\\nClassification Report (Decision Tree):\\n', classification_report(y_test, y_dt, zero_division=0))\n",
        "print('\\nClassification Report (Naive Bayes):\\n', classification_report(y_test, y_nb, zero_division=0))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Save models and dataset\n",
        "os.makedirs('outputs', exist_ok=True)\n",
        "joblib.dump(dt, 'outputs/decision_tree.joblib')\n",
        "joblib.dump(nb, 'outputs/naive_bayes.joblib')\n",
        "model_df.to_csv('outputs/model_dataset.csv', index=False)\n",
        "print('Artifacts saved in outputs/')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Comparison graphs\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "# Bar chart of metrics\n",
        "metrics_names = ['accuracy','precision','recall','f1','roc_auc']\n",
        "dt_values = [dt_metrics[m] for m in metrics_names]\n",
        "nb_values = [nb_metrics[m] for m in metrics_names]\n",
        "\n",
        "x = np.arange(len(metrics_names))\n",
        "width = 0.35\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10,5))\n",
        "ax.bar(x - width/2, dt_values, width, label='Decision Tree')\n",
        "ax.bar(x + width/2, nb_values, width, label='Naive Bayes')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(metrics_names)\n",
        "ax.set_ylabel('Score')\n",
        "ax.set_title('Metrics Comparison')\n",
        "ax.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Confusion matrices\n",
        "fig, axes = plt.subplots(1,2, figsize=(12,5))\n",
        "ConfusionMatrixDisplay.from_estimator(dt, X_test, y_test, ax=axes[0], cmap='Blues')\n",
        "axes[0].set_title('Decision Tree Confusion Matrix')\n",
        "ConfusionMatrixDisplay.from_estimator(nb, X_test, y_test, ax=axes[1], cmap='Oranges')\n",
        "axes[1].set_title('Naive Bayes Confusion Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ROC Curves\n",
        "fpr_dt, tpr_dt, _ = roc_curve(y_test, p_dt)\n",
        "fpr_nb, tpr_nb, _ = roc_curve(y_test, p_nb)\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.plot(fpr_dt, tpr_dt, label=f'Decision Tree (AUC={dt_metrics[\"roc_auc\"]})')\n",
        "plt.plot(fpr_nb, tpr_nb, label=f'Naive Bayes (AUC={nb_metrics[\"roc_auc\"]})')\n",
        "plt.plot([0,1],[0,1],'k--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curves')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Decision Tree Feature Importance\n",
        "feat_imp = pd.Series(dt.feature_importances_, index=feature_cols).sort_values(ascending=False)\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.barplot(x=feat_imp.values, y=feat_imp.index, palette='viridis')\n",
        "plt.title('Decision Tree Feature Importance')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Naive Bayes Feature mean/variance table\n",
        "nb_summary = pd.DataFrame({\n",
        "    'Feature': feature_cols,\n",
        "    'Mean_Class0': nb.theta_[0],\n",
        "    'Mean_Class1': nb.theta_[1],\n",
        "    'Var_Class0': nb.sigma_[0],\n",
        "    'Var_Class1': nb.sigma_[1]\n",
        "})\n",
        "nb_summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Data Mining Scalability\n",
        "import time\n",
        "sizes = [1000,2000,4000,8000,len(X_train)]\n",
        "dt_times, nb_times = [], []\n",
        "for s in sizes:\n",
        "    Xs, ys = X_train[:s], y_train[:s]\n",
        "    t0 = time.time(); DecisionTreeClassifier(max_depth=6).fit(Xs,ys); dt_times.append(time.time()-t0)\n",
        "    t0 = time.time(); GaussianNB().fit(Xs,ys); nb_times.append(time.time()-t0)\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(sizes, dt_times, 'o-', label='Decision Tree')\n",
        "plt.plot(sizes, nb_times, 'o-', label='Naive Bayes')\n",
        "plt.xlabel('Training Set Size')\n",
        "plt.ylabel('Training Time (s)')\n",
        "plt.title('Scalability: Rows vs Time')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
